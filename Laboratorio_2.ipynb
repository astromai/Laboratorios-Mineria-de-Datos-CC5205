{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wEL8gfoNqDc"
      },
      "source": [
        "# Scikit-learn y Machine Learning\n",
        "\n",
        "Inspirado por el curso de Xavier Dupré\n",
        "\n",
        "Integrantes: **AGREGUEN SUS NOMBRES COMPLETOS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Instrucciones\n",
        "\n",
        "1.  Trabajen en equipos de dos personas. Salvo excepciones, no se corregirá entregas con menos de dos integrantes.\n",
        "\n",
        "2.  Modifique este archivo `.ipynb` agregando sus respuestas donde corresponda.\n",
        "\n",
        "3.  Para cada pregunta **incluya el código fuente que utilizó para llegar a su respuesta. Respuestas sin código no recibirán puntaje.**.\n",
        "\n",
        "4.  El formato de entrega para esta actividad es un archivo **html**. **Genere un archivo HTML usando Jupyter** y súbalo a U-Cursos. Basta con que un/a integrante haga la entrega. Si ambos/as hacen una entrega en U-Cursos, se revisará cualquiera de éstas.\n",
        "\n",
        "\n",
        "#### **Se recomienda fuertemente que no usen ChatGPT para resolver la actividad, ya que la experiencia de aprendizaje es mucho mayor si lo hacen por su cuenta.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hM1vmrYyNqDe"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooF9dVasNqDg"
      },
      "source": [
        "## Datos Sintéticos\n",
        "\n",
        "Simulamos un dataset de datos aleatorios con una distribución uniforme $\\mathcal{U}_{(0,1)}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YoYGRSQQNqDh",
        "outputId": "23ac0c17-dcdf-43e6-d0a2-f806cbbad870"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.69270202, 0.90180288],\n",
              "       [0.11078339, 0.5872793 ],\n",
              "       [0.04881203, 0.30842256],\n",
              "       [0.27894601, 0.24958187],\n",
              "       [0.38654803, 0.57929299]])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from numpy import random\n",
        "n = 1000\n",
        "X = random.rand(n, 2)\n",
        "X[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d_uknGgNqDi"
      },
      "source": [
        "Creemos un modelo inicial: $Y = 3 X_1 - 2 X_2^2 + \\epsilon$.\n",
        "\n",
        "Necesitamos aproximar $Y$ usando descriptores $X_1$ y $X_2$.\n",
        "\n",
        "$\\epsilon $~$ \\mathcal{U}_{(0,1)}$ es una fuente de ruido que no podemos controlar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ETrhlnynNqDi",
        "outputId": "b3afe524-b447-4b19-cc1e-039a76b1f11a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.49224144, 0.45588586, 0.92163658, 0.86701042, 0.75140983])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = X[:, 0] * 3 - 2 * X[:, 1] ** 2 + random.rand(n)\n",
        "y[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE9lf5fZNqDk"
      },
      "source": [
        "## Ejercicio 1: Dividiendo en datos de entrenamiento y testeo\n",
        "\n",
        "Debemos testear nuestro modelo con datos distintos a los usados para entrenarlo **para poder medir su capacidad de generalización**. Como hemos visto, el riesgo empírico en un conjunto de datos dado no es representativo del riesgo general, y podemos observar un fenómeno de sobreaprendizaje (overfitting) en el conjunto de entrenamiento.\n",
        "\n",
        "En nuestro caso, queremos que el modelo aprenda la ley $3 X_1 - 2 X_2^2$ y **el sobreaprendizaje equivaldría a memorizar el vector de ruido $\\epsilon$** que solo corresponde a variaciones en $Y$ independientes de nuestro modelo.\n",
        "\n",
        "Simple [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "z0Qy8HORNqDl"
      },
      "outputs": [],
      "source": [
        "# to fill\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val_and_test, y_train, y_val_and_test = train_test_split(X, y, test_size=0.7, random_state=0)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_and_test, y_val_and_test, test_size=0.5, random_state=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sRruykmNqDm"
      },
      "source": [
        "## Ejercicio 2: Entrenar una regresión lineal\n",
        "\n",
        "Encuentre los parámetros $\\theta = \\begin{pmatrix}\n",
        "           \\theta_{1} \\\\\n",
        "           \\theta_{2}\n",
        "         \\end{pmatrix}$ solución de $\\underset{\\theta}{\\arg\\max} \\sum_{i=1}^{n}|Y_i-f_{\\theta}(\\mathbf{X}_i)|^2$\n",
        "         \n",
        "Donde $f_{\\theta}(\\mathbf{X}) = \\theta_0 + \\sum_{d=1}^{D}\\theta_d X_d$ en el caso $D=2$\n",
        "\n",
        "Calcule el coeficiente $R^2$.\n",
        "$$R^2=1-\\frac{\\sum_{i=1}^{n}|Y_i-f(\\mathbf{X}_i)|^2}{\\sum_{i=1}^{n}|Y_i-\\overline{Y}|^2}$$\n",
        "\n",
        "Donde $\\mathbf{X} = \\begin{pmatrix}\n",
        "           X_{1} \\\\\n",
        "           X_{2}\n",
        "         \\end{pmatrix}$ et $\\overline{Y}=\\frac{1}{n}\\sum_{i=1}^{n}Y_i$\n",
        "\n",
        "Use : [LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html), [r2_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "KNfwy8u2NqDm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "thetha1 = 2.9713711336079673 theta2 = -2.0295424026888367\n",
            "r2_score = 0.9046052354127478\n"
          ]
        }
      ],
      "source": [
        "# to fill\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "reg = LinearRegression().fit(X_train, y_train)\n",
        "theta1 = reg.coef_[0]\n",
        "theta2 = reg.coef_[1]\n",
        "print(f\"thetha1 = {theta1} theta2 = {theta2}\")\n",
        "\n",
        "y_pred = reg.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"r2_score = {r2}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z34LAaagNqDn"
      },
      "source": [
        "## Ejercicio 3: Mejorando el modelo aplicando una transformación apropiada\n",
        "\n",
        "El modelo inicial es: $Y = 3 X_1 - 2 X_2^2 + \\epsilon$. Simplemente agregue carecterísticas polinómicas con [PolynomialFeatures](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html).\n",
        "\n",
        "Tomando el parámetro :\n",
        "```python\n",
        "degree=2\n",
        "```\n",
        "El descriptor original $\\mathbf{X} = \\begin{pmatrix} X_{1} \\\\ X_{2} \\end{pmatrix}$\n",
        "Ahora será $\\mathbf{X} = \\begin{pmatrix} 1 \\\\ X_{1} \\\\ X_{2} \\\\ X_{1}^2 \\\\ X_{1}X_{2} \\\\ X_{2}^2 \\end{pmatrix}$ lo que nos da:\n",
        "\n",
        "$$f_{\\theta}(\\mathbf{X}) = \\theta'_0 + \\theta_1 X_1 + \\theta_2 X_2 + \\theta_3 X_1^2 + \\theta_4 X_1X_2 + \\theta_5 X_2^2$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "aVw1wmLzNqDn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train poly:[[1.         0.93358105 0.08464687 0.87157358 0.07902471 0.00716509]\n",
            " [1.         0.52992892 0.77177915 0.28082466 0.40898809 0.59564306]\n",
            " [1.         0.76096529 0.36372399 0.57906817 0.27678133 0.13229514]\n",
            " ...\n",
            " [1.         0.33459686 0.84252262 0.11195506 0.28190542 0.70984437]\n",
            " [1.         0.74714455 0.78077889 0.55822497 0.58335469 0.60961567]\n",
            " [1.         0.26296244 0.24235879 0.06914924 0.06373126 0.05873778]]\n",
            "Test poly: [[1.         0.93845134 0.42834468 0.88069091 0.40198064 0.18347917]\n",
            " [1.         0.80962445 0.16776211 0.65549174 0.1358243  0.02814412]\n",
            " [1.         0.64198065 0.19814688 0.41213915 0.12720646 0.03926219]\n",
            " ...\n",
            " [1.         0.84911609 0.23878287 0.72099813 0.20275437 0.05701726]\n",
            " [1.         0.92064891 0.59197797 0.84759442 0.54500387 0.35043791]\n",
            " [1.         0.38746084 0.63171403 0.1501259  0.24476445 0.39906261]]\n"
          ]
        }
      ],
      "source": [
        "# to fill\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "X_test_poly = poly.fit_transform(X_test)\n",
        "\n",
        "print(f\"Train poly:{X_train_poly}\")\n",
        "print(f\"Test poly: {X_test_poly}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMluQbrpNqDo"
      },
      "source": [
        "## Ejercicio 4: entrenar un Random Forest\n",
        "\n",
        "Use: [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.894207808544904"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "clf = RandomForestRegressor()\n",
        "# learning classifier\n",
        "clf.fit(X_train, y_train)\n",
        "# scoring classifier\n",
        "clf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Veamos ahora las características polinómicas..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.893632021750373"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# to fill\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "clf.fit(X_train_poly, y_train)\n",
        "\n",
        "clf.score(X_test_poly, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXhWgKOLNqDo"
      },
      "source": [
        "## Ejercicio 5: Un poco de matemáticas\n",
        "\n",
        "Compare ambos modelos con los siguientes datos. De qué se puede percatar? Por qué?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "8rZMCvc-NqDo"
      },
      "outputs": [],
      "source": [
        "X_test2 = random.rand(n, 2) + 0.5\n",
        "y_test2 = X_test2[:, 0] * 3 - 2 * X_test2[:, 1] ** 2 + random.rand(n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8D7f_55NqDp"
      },
      "outputs": [],
      "source": [
        "# to fill"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAhnCrQ3NqDp"
      },
      "source": [
        "## Ejercicio 6: Ilustrando el overfitting con un árbol de decisión\n",
        "\n",
        "A medida que la complejidad del modelo aumenta, el overfitting ocurre. Análogamente, el modelo usando solo $X_1$ y $X_2$ no está necesariamente adaptado al problema y cae en un caso underfitting. Grafique cómo evoluciona la R2 según la profundidad del decision tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLYkgE5vNqDp"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "res = []\n",
        "for md in range(1, 20):\n",
        "    # to fill\n",
        "\n",
        "    res.append(dict(profondeur=md, r2_train=r2_train, r2_test=r2_test))\n",
        "\n",
        "df = pandas.DataFrame(res)\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5ewy8oLNqDq"
      },
      "outputs": [],
      "source": [
        "ax = df.plot(x='profondeur', y=['r2_train', 'r2_test'])\n",
        "ax.set_title(\"Evolution du R2 selon la profondeur\");"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
