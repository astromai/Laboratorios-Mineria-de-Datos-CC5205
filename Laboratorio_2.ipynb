{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wEL8gfoNqDc"
      },
      "source": [
        "# Scikit-learn y Machine Learning\n",
        "\n",
        "Inspirado por el curso de Xavier Dupré\n",
        "\n",
        "Integrantes: **AGREGUEN SUS NOMBRES COMPLETOS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Instrucciones\n",
        "\n",
        "1.  Trabajen en equipos de dos personas. Salvo excepciones, no se corregirá entregas con menos de dos integrantes.\n",
        "\n",
        "2.  Modifique este archivo `.ipynb` agregando sus respuestas donde corresponda.\n",
        "\n",
        "3.  Para cada pregunta **incluya el código fuente que utilizó para llegar a su respuesta. Respuestas sin código no recibirán puntaje.**.\n",
        "\n",
        "4.  El formato de entrega para esta actividad es un archivo **html**. **Genere un archivo HTML usando Jupyter** y súbalo a U-Cursos. Basta con que un/a integrante haga la entrega. Si ambos/as hacen una entrega en U-Cursos, se revisará cualquiera de éstas.\n",
        "\n",
        "\n",
        "#### **Se recomienda fuertemente que no usen ChatGPT para resolver la actividad, ya que la experiencia de aprendizaje es mucho mayor si lo hacen por su cuenta.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hM1vmrYyNqDe"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooF9dVasNqDg"
      },
      "source": [
        "## Datos Sintéticos\n",
        "\n",
        "Simulamos un dataset de datos aleatorios con una distribución uniforme $\\mathcal{U}_{(0,1)}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YoYGRSQQNqDh",
        "outputId": "23ac0c17-dcdf-43e6-d0a2-f806cbbad870"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.43469334, 0.03034804],\n",
              "       [0.65470217, 0.68547082],\n",
              "       [0.86739388, 0.57413359],\n",
              "       [0.61268425, 0.34685454],\n",
              "       [0.45315557, 0.59184804]])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from numpy import random\n",
        "n = 1000\n",
        "X = random.rand(n, 2)\n",
        "X[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d_uknGgNqDi"
      },
      "source": [
        "Creemos un modelo inicial: $Y = 3 X_1 - 2 X_2^2 + \\epsilon$.\n",
        "\n",
        "Necesitamos aproximar $Y$ usando descriptores $X_1$ y $X_2$.\n",
        "\n",
        "$\\epsilon $~$ \\mathcal{U}_{(0,1)}$ es una fuente de ruido que no podemos controlar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ETrhlnynNqDi",
        "outputId": "b3afe524-b447-4b19-cc1e-039a76b1f11a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1.51953716, 1.24110068, 2.23160799, 1.7226841 , 1.53132901])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = X[:, 0] * 3 - 2 * X[:, 1] ** 2 + random.rand(n)\n",
        "y[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE9lf5fZNqDk"
      },
      "source": [
        "## Ejercicio 1: Dividiendo en datos de entrenamiento y testeo\n",
        "\n",
        "Debemos testear nuestro modelo con datos distintos a los usados para entrenarlo **para poder medir su capacidad de generalización**. Como hemos visto, el riesgo empírico en un conjunto de datos dado no es representativo del riesgo general, y podemos observar un fenómeno de sobreaprendizaje (overfitting) en el conjunto de entrenamiento.\n",
        "\n",
        "En nuestro caso, queremos que el modelo aprenda la ley $3 X_1 - 2 X_2^2$ y **el sobreaprendizaje equivaldría a memorizar el vector de ruido $\\epsilon$** que solo corresponde a variaciones en $Y$ independientes de nuestro modelo.\n",
        "\n",
        "Simple [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0Qy8HORNqDl"
      },
      "outputs": [],
      "source": [
        "# to fill\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val_and_test, y_train, y_val_and_test = train_test_split(X, y, test_size=0.7, random_state=0)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_and_test, y_val_and_test, test_size=0.5, random_state=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sRruykmNqDm"
      },
      "source": [
        "## Ejercicio 2: Entrenar una regresión lineal\n",
        "\n",
        "Encuentre los parámetros $\\theta = \\begin{pmatrix}\n",
        "           \\theta_{1} \\\\\n",
        "           \\theta_{2}\n",
        "         \\end{pmatrix}$ solución de $\\underset{\\theta}{\\arg\\max} \\sum_{i=1}^{n}|Y_i-f_{\\theta}(\\mathbf{X}_i)|^2$\n",
        "         \n",
        "Donde $f_{\\theta}(\\mathbf{X}) = \\theta_0 + \\sum_{d=1}^{D}\\theta_d X_d$ en el caso $D=2$\n",
        "\n",
        "Calcule el coeficiente $R^2$.\n",
        "$$R^2=1-\\frac{\\sum_{i=1}^{n}|Y_i-f(\\mathbf{X}_i)|^2}{\\sum_{i=1}^{n}|Y_i-\\overline{Y}|^2}$$\n",
        "\n",
        "Donde $\\mathbf{X} = \\begin{pmatrix}\n",
        "           X_{1} \\\\\n",
        "           X_{2}\n",
        "         \\end{pmatrix}$ et $\\overline{Y}=\\frac{1}{n}\\sum_{i=1}^{n}Y_i$\n",
        "\n",
        "Use : [LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html), [r2_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KNfwy8u2NqDm"
      },
      "outputs": [],
      "source": [
        "# to fill"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z34LAaagNqDn"
      },
      "source": [
        "## Ejercicio 3: Mejorando el modelo aplicando una transformación apropiada\n",
        "\n",
        "El modelo inicial es: $Y = 3 X_1 - 2 X_2^2 + \\epsilon$. Simplemente agregue carecterísticas polinómicas con [PolynomialFeatures](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html).\n",
        "\n",
        "Tomando el parámetro :\n",
        "```python\n",
        "degree=2\n",
        "```\n",
        "El descriptor original $\\mathbf{X} = \\begin{pmatrix} X_{1} \\\\ X_{2} \\end{pmatrix}$\n",
        "Ahora será $\\mathbf{X} = \\begin{pmatrix} 1 \\\\ X_{1} \\\\ X_{2} \\\\ X_{1}^2 \\\\ X_{1}X_{2} \\\\ X_{2}^2 \\end{pmatrix}$ lo que nos da:\n",
        "\n",
        "$$f_{\\theta}(\\mathbf{X}) = \\theta'_0 + \\theta_1 X_1 + \\theta_2 X_2 + \\theta_3 X_1^2 + \\theta_4 X_1X_2 + \\theta_5 X_2^2$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aVw1wmLzNqDn"
      },
      "outputs": [],
      "source": [
        "# to fill"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMluQbrpNqDo"
      },
      "source": [
        "## Ejercicio 4: entrenar un Random Forest\n",
        "\n",
        "Use: [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "clf = RandomForestRegressor()\n",
        "# learning classifier\n",
        "clf.fit(X_train, y_train)\n",
        "# scoring classifier\n",
        "clf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Veamos ahora las características polinómicas..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# to fill"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXhWgKOLNqDo"
      },
      "source": [
        "## Ejercicio 5: Un poco de matemáticas\n",
        "\n",
        "Compare ambos modelos con los siguientes datos. De qué se puede percatar? Por qué?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rZMCvc-NqDo"
      },
      "outputs": [],
      "source": [
        "X_test2 = random.rand(n, 2) + 0.5\n",
        "y_test2 = X_test2[:, 0] * 3 - 2 * X_test2[:, 1] ** 2 + random.rand(n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8D7f_55NqDp"
      },
      "outputs": [],
      "source": [
        "# to fill"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAhnCrQ3NqDp"
      },
      "source": [
        "## Ejercicio 6: Ilustrando el overfitting con un árbol de decisión\n",
        "\n",
        "A medida que la complejidad del modelo aumenta, el overfitting ocurre. Análogamente, el modelo usando solo $X_1$ y $X_2$ no está necesariamente adaptado al problema y cae en un caso underfitting. Grafique cómo evoluciona la R2 según la profundidad del decision tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLYkgE5vNqDp"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "res = []\n",
        "for md in range(1, 20):\n",
        "    # to fill\n",
        "\n",
        "    res.append(dict(profondeur=md, r2_train=r2_train, r2_test=r2_test))\n",
        "\n",
        "df = pandas.DataFrame(res)\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5ewy8oLNqDq"
      },
      "outputs": [],
      "source": [
        "ax = df.plot(x='profondeur', y=['r2_train', 'r2_test'])\n",
        "ax.set_title(\"Evolution du R2 selon la profondeur\");"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
