{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wEL8gfoNqDc"
      },
      "source": [
        "# Scikit-learn y Machine Learning\n",
        "\n",
        "Inspirado por el curso de Xavier Dupré\n",
        "\n",
        "Integrantes: **AGREGUEN SUS NOMBRES COMPLETOS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Instrucciones\n",
        "\n",
        "1.  Trabajen en equipos de dos personas. Salvo excepciones, no se corregirá entregas con menos de dos integrantes.\n",
        "\n",
        "2.  Modifique este archivo `.ipynb` agregando sus respuestas donde corresponda.\n",
        "\n",
        "3.  Para cada pregunta **incluya el código fuente que utilizó para llegar a su respuesta. Respuestas sin código no recibirán puntaje.**.\n",
        "\n",
        "4.  El formato de entrega para esta actividad es un archivo **html**. **Genere un archivo HTML usando Jupyter** y súbalo a U-Cursos. Basta con que un/a integrante haga la entrega. Si ambos/as hacen una entrega en U-Cursos, se revisará cualquiera de éstas.\n",
        "\n",
        "\n",
        "#### **Se recomienda fuertemente que no usen ChatGPT para resolver la actividad, ya que la experiencia de aprendizaje es mucho mayor si lo hacen por su cuenta.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hM1vmrYyNqDe"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooF9dVasNqDg"
      },
      "source": [
        "## Datos Sintéticos\n",
        "\n",
        "Simulamos un dataset de datos aleatorios con una distribución uniforme $\\mathcal{U}_{(0,1)}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YoYGRSQQNqDh",
        "outputId": "23ac0c17-dcdf-43e6-d0a2-f806cbbad870"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.61681828, 0.06624273],\n",
              "       [0.14753923, 0.81687606],\n",
              "       [0.66720883, 0.91560666],\n",
              "       [0.94545977, 0.60519192],\n",
              "       [0.40581235, 0.02014857]])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from numpy import random\n",
        "n = 1000\n",
        "X = random.rand(n, 2)\n",
        "X[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d_uknGgNqDi"
      },
      "source": [
        "Creemos un modelo inicial: $Y = 3 X_1 - 2 X_2^2 + \\epsilon$.\n",
        "\n",
        "Necesitamos aproximar $Y$ usando descriptores $X_1$ y $X_2$.\n",
        "\n",
        "$\\epsilon $~$ \\mathcal{U}_{(0,1)}$ es una fuente de ruido que no podemos controlar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ETrhlnynNqDi",
        "outputId": "b3afe524-b447-4b19-cc1e-039a76b1f11a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1.89657501, -0.45152944,  0.91452153,  2.9084734 ,  2.12707393])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = X[:, 0] * 3 - 2 * X[:, 1] ** 2 + random.rand(n)\n",
        "y[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE9lf5fZNqDk"
      },
      "source": [
        "## Ejercicio 1: Dividiendo en datos de entrenamiento y testeo\n",
        "\n",
        "Debemos testear nuestro modelo con datos distintos a los usados para entrenarlo **para poder medir su capacidad de generalización**. Como hemos visto, el riesgo empírico en un conjunto de datos dado no es representativo del riesgo general, y podemos observar un fenómeno de sobreaprendizaje (overfitting) en el conjunto de entrenamiento.\n",
        "\n",
        "En nuestro caso, queremos que el modelo aprenda la ley $3 X_1 - 2 X_2^2$ y **el sobreaprendizaje equivaldría a memorizar el vector de ruido $\\epsilon$** que solo corresponde a variaciones en $Y$ independientes de nuestro modelo.\n",
        "\n",
        "Simple [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "z0Qy8HORNqDl"
      },
      "outputs": [],
      "source": [
        "# to fill\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val_and_test, y_train, y_val_and_test = train_test_split(X, y, test_size=0.7, random_state=0)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_and_test, y_val_and_test, test_size=0.5, random_state=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sRruykmNqDm"
      },
      "source": [
        "## Ejercicio 2: Entrenar una regresión lineal\n",
        "\n",
        "Encuentre los parámetros $\\theta = \\begin{pmatrix}\n",
        "           \\theta_{1} \\\\\n",
        "           \\theta_{2}\n",
        "         \\end{pmatrix}$ solución de $\\underset{\\theta}{\\arg\\max} \\sum_{i=1}^{n}|Y_i-f_{\\theta}(\\mathbf{X}_i)|^2$\n",
        "         \n",
        "Donde $f_{\\theta}(\\mathbf{X}) = \\theta_0 + \\sum_{d=1}^{D}\\theta_d X_d$ en el caso $D=2$\n",
        "\n",
        "Calcule el coeficiente $R^2$.\n",
        "$$R^2=1-\\frac{\\sum_{i=1}^{n}|Y_i-f(\\mathbf{X}_i)|^2}{\\sum_{i=1}^{n}|Y_i-\\overline{Y}|^2}$$\n",
        "\n",
        "Donde $\\mathbf{X} = \\begin{pmatrix}\n",
        "           X_{1} \\\\\n",
        "           X_{2}\n",
        "         \\end{pmatrix}$ et $\\overline{Y}=\\frac{1}{n}\\sum_{i=1}^{n}Y_i$\n",
        "\n",
        "Use : [LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html), [r2_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KNfwy8u2NqDm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "thetha1 = 3.0414256880876223 theta2 = -2.1348582248747503\n",
            "r2_score = 0.9078521448291386\n"
          ]
        }
      ],
      "source": [
        "# to fill\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "reg = LinearRegression().fit(X_train, y_train)\n",
        "theta1 = reg.coef_[0]\n",
        "theta2 = reg.coef_[1]\n",
        "print(f\"thetha1 = {theta1} theta2 = {theta2}\")\n",
        "\n",
        "y_pred = reg.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"r2_score = {r2}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z34LAaagNqDn"
      },
      "source": [
        "## Ejercicio 3: Mejorando el modelo aplicando una transformación apropiada\n",
        "\n",
        "El modelo inicial es: $Y = 3 X_1 - 2 X_2^2 + \\epsilon$. Simplemente agregue carecterísticas polinómicas con [PolynomialFeatures](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html).\n",
        "\n",
        "Tomando el parámetro :\n",
        "```python\n",
        "degree=2\n",
        "```\n",
        "El descriptor original $\\mathbf{X} = \\begin{pmatrix} X_{1} \\\\ X_{2} \\end{pmatrix}$\n",
        "Ahora será $\\mathbf{X} = \\begin{pmatrix} 1 \\\\ X_{1} \\\\ X_{2} \\\\ X_{1}^2 \\\\ X_{1}X_{2} \\\\ X_{2}^2 \\end{pmatrix}$ lo que nos da:\n",
        "\n",
        "$$f_{\\theta}(\\mathbf{X}) = \\theta'_0 + \\theta_1 X_1 + \\theta_2 X_2 + \\theta_3 X_1^2 + \\theta_4 X_1X_2 + \\theta_5 X_2^2$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "aVw1wmLzNqDn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "thetha1 = 0.0 theta2 = 3.651162566184459\n",
            "r2_score = 0.9248528830419992\n"
          ]
        }
      ],
      "source": [
        "# to fill\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "X_test_poly = poly.fit_transform(X_test)\n",
        "\n",
        "reg2 = LinearRegression().fit(X_train_poly, y_train)\n",
        "theta11 = reg2.coef_[0]\n",
        "theta22 = reg2.coef_[1]\n",
        "print(f\"thetha1 = {theta11} theta2 = {theta22}\")\n",
        "\n",
        "y_pred_poly = reg2.predict(X_test_poly)\n",
        "r2_poly = r2_score(y_test, y_pred_poly)\n",
        "\n",
        "print(f\"r2_score = {r2_poly}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMluQbrpNqDo"
      },
      "source": [
        "## Ejercicio 4: entrenar un Random Forest\n",
        "\n",
        "Use: [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9046279872780306"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "clf = RandomForestRegressor()\n",
        "# learning classifier\n",
        "clf.fit(X_train, y_train)\n",
        "# scoring classifier\n",
        "clf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Veamos ahora las características polinómicas..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9061204855617153"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# to fill\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "clf.fit(X_train_poly, y_train)\n",
        "\n",
        "clf.score(X_test_poly, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXhWgKOLNqDo"
      },
      "source": [
        "## Ejercicio 5: Un poco de matemáticas\n",
        "\n",
        "Compare ambos modelos con los siguientes datos. De qué se puede percatar? Por qué?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8rZMCvc-NqDo"
      },
      "outputs": [],
      "source": [
        "X_test2 = random.rand(n, 2) + 0.5\n",
        "y_test2 = X_test2[:, 0] * 3 - 2 * X_test2[:, 1] ** 2 + random.rand(n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E8D7f_55NqDp"
      },
      "outputs": [],
      "source": [
        "# to fill\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAhnCrQ3NqDp"
      },
      "source": [
        "## Ejercicio 6: Ilustrando el overfitting con un árbol de decisión\n",
        "\n",
        "A medida que la complejidad del modelo aumenta, el overfitting ocurre. Análogamente, el modelo usando solo $X_1$ y $X_2$ no está necesariamente adaptado al problema y cae en un caso underfitting. Grafique cómo evoluciona la R2 según la profundidad del decision tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XLYkgE5vNqDp"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'r2_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m res \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m md \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m20\u001b[39m):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# to fill\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     res\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mdict\u001b[39m(profondeur\u001b[38;5;241m=\u001b[39mmd, r2_train\u001b[38;5;241m=\u001b[39m\u001b[43mr2_train\u001b[49m, r2_test\u001b[38;5;241m=\u001b[39mr2_test))\n\u001b[1;32m      9\u001b[0m df \u001b[38;5;241m=\u001b[39m pandas\u001b[38;5;241m.\u001b[39mDataFrame(res)\n\u001b[1;32m     10\u001b[0m df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'r2_train' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "res = []\n",
        "for md in range(1, 20):\n",
        "    # to fill\n",
        "\n",
        "    res.append(dict(profondeur=md, r2_train=r2_train, r2_test=r2_test))\n",
        "\n",
        "df = pandas.DataFrame(res)\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5ewy8oLNqDq"
      },
      "outputs": [],
      "source": [
        "ax = df.plot(x='profondeur', y=['r2_train', 'r2_test'])\n",
        "ax.set_title(\"Evolution du R2 selon la profondeur\");"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
